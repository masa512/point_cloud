{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMi3oA8G8ji/C6ehWQFnH6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masa512/point_cloud/blob/main/PC_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m_H7NJjJMYy9"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAB Model\n",
        "\n",
        "Set Attention Block utilizes the input set to locally decide which part of the set to focus on. The SAB is defined as the following\n",
        "\n",
        "MAB(X,X)"
      ],
      "metadata": {
        "id": "sA0DMzdQMzRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAB(nn.Module):\n",
        "  def __init__(self,dim_Q, dim_K, dim_V, n_heads):\n",
        "    super(MAB,self).__init__()\n",
        "    self.dim_V = dim_V # Important since this is the output dimension\n",
        "    self.n_heads = n_heads\n",
        "\n",
        "    # Define the fully connected layer for key, val, query transform\n",
        "    self.wk = nn.Linear(dim_K,self.dim_V)\n",
        "    self.wq = nn.Linear(dim_Q,self.dim_V)\n",
        "    self.wv = nn.Linear(dim_K,self.dim_V)\n",
        "\n",
        "    self.ln = nn.LayerNorm(dim_V)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self,query,key,value):\n",
        "    # Projection\n",
        "    print(key.shape)\n",
        "    K = self.wk(key)\n",
        "    V = self.wv(value)\n",
        "    Q = self.wq(query)\n",
        "\n",
        "    batch_size = K.shape[0]\n",
        "\n",
        "    # Good to note -> Batch,seq_len,emb_dim\n",
        "    # Splitting ideally should give -> Batch,n_heads,seq_len,emb_dim\n",
        "\n",
        "    # Let's reshape the input beforehand\n",
        "    p_size = self.dim_V // self.n_heads\n",
        "    K_split = torch.split(K,split_size_or_sections=p_size, dim = -1)\n",
        "    V_split = torch.split(V,split_size_or_sections=p_size, dim = -1)\n",
        "    Q_split = torch.split(Q,split_size_or_sections=p_size, dim = -1)\n",
        "\n",
        "    K_ = torch.stack(K_split,dim=1)\n",
        "    V_ = torch.stack(V_split,dim=1)\n",
        "    Q_ = torch.stack(Q_split,dim=1)\n",
        "\n",
        "    # Now the dot product activation\n",
        "\n",
        "    A = torch.bmm(Q_.view(-1,Q_.shape[-2],Q_.shape[-1]),torch.transpose(K_.view(-1,K_.shape[-2],K_.shape[-1]),-1,-2))/math.sqrt(self.dim_V)\n",
        "    A = A.reshape(batch_size,-1,A.shape[-2],A.shape[-1])\n",
        "    # Softmax activation across embedding dimension\n",
        "    SM = nn.Softmax(dim=-1)\n",
        "    A = SM(A)\n",
        "\n",
        "\n",
        "    \n",
        "    # Apply activation on the Value and concatenate result\n",
        "    Y = torch.bmm(A.view(-1,A.shape[-2],A.shape[-1]),V_.view(-1,V_.shape[-2],V_.shape[-1])) # Output with dim Batch, n_heads, seq_len, p_dim \n",
        "    Y = Y.reshape((batch_size,-1,Y.shape[-2],Y.shape[-1]))\n",
        "    # Reorganize the dimensions to have Batch, seq_len, n_heads, p_dim\n",
        "    Y = torch.permute(Y,dims=(0,2,1,3))\n",
        "    Y = Y.reshape((Y.shape[0],Y.shape[1],-1))\n",
        "\n",
        "    # Apply layer norm \n",
        "    Y = self.ln(Y)\n",
        "    # Relu\n",
        "    Y = self.relu(Y)\n",
        "    return Y\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jUEIXqZdeKB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAB(nn.Module):\n",
        "  \n",
        "  def __init__(self,in_dim,out_dim,n_heads):\n",
        "    super(SAB,self).__init__()\n",
        "    self.in_dim = in_dim\n",
        "    self.out_dim = out_dim\n",
        "\n",
        "    # Initialize the SAB Block\n",
        "    self.MAB = MAB(dim_Q = in_dim, dim_K = in_dim, dim_V = out_dim, n_heads = n_heads)\n",
        "    \n",
        "  def forward(self,X):\n",
        "    Y = self.MAB(query = X,key = X,value = X)\n",
        "\n",
        "    return Y\n"
      ],
      "metadata": {
        "id": "eVaTZccBMfhu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ISAB(nn.Module):\n",
        "\n",
        "  def __init__(self,in_dim,out_dim,n_heads,compressed_len):\n",
        "    super(ISAB,self).__init__()\n",
        "    self.in_dim = in_dim \n",
        "    self.out_dim = out_dim # Hidden dimension (latent)\n",
        "\n",
        "    # Initialize the MAB Block here\n",
        "    self.MAB1 = MAB(out_dim, in_dim, out_dim, n_heads)\n",
        "    self.MAB2 = MAB(in_dim, out_dim, out_dim,n_heads)\n",
        "    # Build a trainable tensor I that serves as the length_reduction query\n",
        "    self.I = nn.Parameter(torch.Tensor(1,compressed_len,out_dim))\n",
        "    nn.init.xavier_uniform_(self.I) # Xavier uniform dist.initialization\n",
        "\n",
        "  def forward(self,X):\n",
        "    H = self.MAB1(query = self.I.repeat(X.shape[0],1,1), key = X,value = X)\n",
        "    Y = self.MAB2(query = X, key = H, value = H)\n",
        "    return Y\n"
      ],
      "metadata": {
        "id": "YJKFh1oQUOWN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PMA(nn.Module):\n",
        "  # This one preserves the input embedding dimmension, just for channel-wise operation\n",
        "  def __init__(self,embedding_dim, n_heads, out_length):\n",
        "    super(PMA,self).__init__()\n",
        "    self.MAB = MAB(embedding_dim,embedding_dim,embedding_dim,n_heads)\n",
        "    self.S = nn.Parameter(torch.Tensor(1,out_length,embedding_dim))\n",
        "    nn.init.xavier_uniform_(self.S)\n",
        "\n",
        "  def forward(self,X):\n",
        "    Y = self.MAB(query = self.S.repeat(X.shape[0],1,1), value = X, key=X)\n",
        "    return Y\n"
      ],
      "metadata": {
        "id": "Rqyg0O1f34Ki"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the MAB functionality"
      ],
      "metadata": {
        "id": "gdmSdmCL8Wkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "seq_len = 100\n",
        "\n",
        "# Define a batch of random array of length seq_len\n",
        "rand_seq = torch.rand(size=(seq_len,))\n",
        "\n",
        "# We will only sample 75% indices from here\n",
        "percentage = 0.75\n",
        "N_sample = int(0.75*seq_len)\n",
        "rand_indices = random.sample(range(seq_len),N_sample)\n",
        "corr_values = torch.Tensor([rand_seq[i] for i in rand_indices])\n",
        "# We will build a new tensor that appends the position on the audio sequence [idx,x]\n",
        "X = torch.stack([torch.Tensor(rand_indices),corr_values],dim=-1)\n",
        "X = X.reshape(1,X.shape[0],X.shape[1])\n"
      ],
      "metadata": {
        "id": "9HPsfDoq8Soc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data on the numberline for fun\n",
        "import matplotlib.pyplot as plt \n",
        "f = plt.scatter(X[0,:,0],X[0,:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "hh-JQxI1-DDt",
        "outputId": "19372a75-b4d1-4b3a-924e-77a9f51d7548"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a MAB Block\n",
        "dim_Q = 2\n",
        "dim_K = 2\n",
        "dim_V = 2\n",
        "n_heads = 1\n",
        "model = MAB(dim_Q, dim_K, dim_V, n_heads)\n",
        "\n",
        "# Forward_pass\n",
        "Y = model(query = X,key = X, value = X)\n",
        "\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMQ7c1vHElHM",
        "outputId": "84248b6f-cc08-40dd-e47b-178440f31673"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 75, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a SAB Block\n",
        "in_dim = 2\n",
        "out_dim = 2\n",
        "model = SAB(in_dim,out_dim,n_heads)\n",
        "\n",
        "# Forward_pass\n",
        "Y = model(X)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WDhx_PbLU4S",
        "outputId": "e0da4c96-bb81-4f4f-d830-f5f0ab300dc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 75, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a ISAB Block\n",
        "in_dim = 2\n",
        "out_dim = 3\n",
        "compressed_len = 30\n",
        "model = ISAB(in_dim,out_dim,n_heads,compressed_len)\n",
        "\n",
        "# Forward Pass\n",
        "Y = model(X)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "bzL4vApeGp79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d4dc26-9b4f-4cd4-d6b2-48ae2afd78f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 75, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PMA Block\n",
        "embedding_dim = 2\n",
        "n_heads = 1\n",
        "out_length = 1\n",
        "\n",
        "model = PMA(embedding_dim, n_heads, out_length)\n",
        "Y = model(X)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCtgDgbfKNTx",
        "outputId": "a326075c-942a-43d3-9978-57723bf1f8d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Encoder-Decoder network"
      ],
      "metadata": {
        "id": "Ajmqdf7LJ906"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class set_transformer(nn.Module):\n",
        "  def __init__(self,in_dim,h_dim,out_dim,out_len,hidden_len,n_heads):\n",
        "    super(set_transformer,self).__init__()\n",
        "    self.enc = nn.Sequential(\n",
        "        ISAB(in_dim=in_dim,out_dim=h_dim,n_heads=n_heads,compressed_len = hidden_len),\n",
        "        ISAB(in_dim=h_dim,out_dim=h_dim,n_heads=n_heads,compressed_len = hidden_len)\n",
        "    )\n",
        "                            \n",
        "    self.dec = nn.Sequential(\n",
        "        PMA(embedding_dim=h_dim, n_heads=n_heads, out_length=out_len),\n",
        "        SAB(in_dim=h_dim, out_dim=h_dim, n_heads=n_heads),\n",
        "        SAB(in_dim=h_dim, out_dim=h_dim, n_heads=n_heads),\n",
        "        nn.Linear(in_features=h_dim, out_features=out_dim)\n",
        "    )\n",
        "  \n",
        "  def forward(self,X):\n",
        "    Y = self.enc(X)\n",
        "    Y = self.dec(Y)\n",
        "    return Y\n"
      ],
      "metadata": {
        "id": "mNqdZ6UiKBtD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the transformer\n",
        "in_dim = 2\n",
        "h_dim = 3\n",
        "out_dim = 5 # num class\n",
        "out_len = 1\n",
        "hidden_len = 20\n",
        "n_heads = 1\n",
        "\n",
        "model = set_transformer(in_dim=in_dim,h_dim=h_dim,out_dim=out_dim,out_len=out_len,hidden_len=hidden_len,n_heads=n_heads)\n",
        "# Run one forward on X\n",
        "Y = model(X)\n",
        "\n",
        "# print the shape\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_1azIDnUrPp",
        "outputId": "774a382f-71e1-41e4-c32c-8893fb9e23c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another test with arbitrary setup\n",
        "in_dim = 129\n",
        "h_dim = 99\n",
        "out_dim = 3 # num class\n",
        "out_len = 1\n",
        "hidden_len = 100\n",
        "n_heads = 3\n",
        "\n",
        "model = set_transformer(in_dim=in_dim,h_dim=h_dim,out_dim=out_dim,out_len=out_len,hidden_len=hidden_len,n_heads=n_heads)\n",
        "\n",
        "X = torch.rand((4,410,129))\n",
        "Y = model(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkUA9_gAMCm0",
        "outputId": "b84eba87-10f8-4c3e-c1ee-b4bb3b464af0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 410, 129])\n",
            "torch.Size([4, 100, 99])\n",
            "torch.Size([4, 410, 99])\n",
            "torch.Size([4, 100, 99])\n",
            "torch.Size([4, 410, 99])\n",
            "torch.Size([4, 1, 99])\n",
            "torch.Size([4, 1, 99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Point-Cloud Audio Classification"
      ],
      "metadata": {
        "id": "S3-FdqAOlMl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "cn7G3ozD0BON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install musdb\n",
        "import musdb\n",
        "mus = musdb.DB(download=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GLZvQsnYVnrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16604772-a67e-4c22-e7f3-321609476cb0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting musdb\n",
            "  Downloading musdb-0.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting stempeg>=0.2.3\n",
            "  Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 KB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from musdb) (4.65.0)\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.9/dist-packages (from musdb) (1.22.4)\n",
            "Collecting ffmpeg-python>=0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyaml->musdb) (6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (0.18.3)\n",
            "Installing collected packages: pyaml, ffmpeg-python, stempeg, musdb\n",
            "Successfully installed ffmpeg-python-0.2.0 musdb-0.4.0 pyaml-21.10.1 stempeg-0.2.3\n",
            "Downloading MUSDB 7s Sample Dataset to /root/MUSDB18/MUSDB18-7...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process dataset to merge all instruments\n",
        "num_tracks = 30\n",
        "DB = mus[:num_tracks]\n",
        "fs = DB[0].rate\n",
        "x = []\n",
        "y = [] # (vocal,0), (bass,1), (drum,2)\n",
        "\n",
        "for n in range(num_tracks):\n",
        "  cur_track = DB[n].targets\n",
        "  # get the vocal\n",
        "  x.append(np.sum(cur_track['vocals'].audio,axis = 1))\n",
        "  y.append(0)\n",
        "\n",
        "  # get the bass\n",
        "  x.append(np.sum(cur_track['bass'].audio,axis = 1))\n",
        "  y.append(1)\n",
        "\n",
        "  # get the drums\n",
        "  x.append(np.sum(cur_track['drums'].audio,axis = 1))\n",
        "  y.append(2)\n",
        "\n",
        "\n",
        "print('data_size:',len(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEgiWozZtPv-",
        "outputId": "23c65f2c-393e-4e79-994f-928d90c04a36"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_size: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clipping\n",
        "class RandomClip:\n",
        "    def __init__(self, fraction):\n",
        "        self.fraction = fraction\n",
        "      \n",
        "\n",
        "    def __call__(self, audio_data):\n",
        "        # Audio datas are stored in list\n",
        "        \n",
        "        audio_length = audio_data[0].shape[0]\n",
        "        clip_length = int(self.fraction * audio_length)\n",
        "        if audio_length > clip_length:\n",
        "          offset = random.randint(0, audio_length-clip_length)\n",
        "          audio_data = [x[offset:(offset+clip_length)] for x in audio_data]\n",
        "\n",
        "        \n",
        "        return audio_data"
      ],
      "metadata": {
        "id": "oBJv4lpP6kSi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloud Audio extractor from STFT\n",
        "def mel_to_cloud(mel_spectrum,frac_keep):\n",
        "  \"\"\"\n",
        "  The sampling in time will be same across all freq axis\n",
        "  Returns (F,1+floor(T*frac_keep)) tensor\n",
        "  \"\"\"\n",
        "  F,T = mel_spectrum.shape\n",
        "  N = int(frac_keep*T)\n",
        "  lst = []\n",
        "  rand_idx = random.sample(range(T),N) # Random indices of time sampled\n",
        "  rand_idx.sort()\n",
        "  # Sampled mel_spectrum\n",
        "  rand_idx = torch.tensor(rand_idx,dtype=torch.long,requires_grad=False)\n",
        "  mel_sampled = mel_spectrum[:,rand_idx]\n",
        "  # Concat the idx onto mel_sampled\n",
        "  Y = torch.concatenate([rand_idx.reshape(1,-1),mel_sampled],dim=0)\n",
        "  \n",
        "  return Y\n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "vQFj9fOLuTCY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "from torchaudio.transforms import MelScale\n",
        "# Define the dataset\n",
        "class lala_dataset(Dataset):\n",
        "\n",
        "  def __init__(self,x,y,fs,n_fft=2048,transform = None,frac_keep = 0.7):\n",
        "\n",
        "    # We will use the DB from our MUSDB but it will be open for the user to replace this functionality\n",
        "    super(lala_dataset,self).__init__()\n",
        "    # We will use just 5 songs\n",
        "    self.X = x\n",
        "    self.Y = y\n",
        "    self.n_fft = n_fft\n",
        "    self.fs = fs\n",
        "    self.trans = transform # Clipping\n",
        "    self.mel_transform = MelScale(n_mels = 128, sample_rate = self.fs, n_stft = self.n_fft)\n",
        "    self.frac_keep = frac_keep # Only keep 70% of available data for simulating lacking there of\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Get audio array and corresponding label\n",
        "    x = torch.tensor(self.X[idx])\n",
        "    y = torch.tensor(self.Y[idx])\n",
        "\n",
        "    # Apply STFT->Mel procedure\n",
        "    S = abs(torch.stft(x,n_fft=self.n_fft,onesided=False, return_complex=True))\n",
        "    S = S.type(torch.float)\n",
        "    mel = self.mel_transform(S)\n",
        "    \n",
        "    # Normalize the spectrogram\n",
        "    eps = 1e-8\n",
        "    log_mel = torch.log(eps + mel)\n",
        "    M = torch.max(log_mel)\n",
        "    m = torch.min(log_mel)\n",
        "\n",
        "    scaled = (log_mel - m)/(M-m)\n",
        "\n",
        "    # Apply mel-to-cloud\n",
        "    C = mel_to_cloud(scaled,frac_keep = self.frac_keep)\n",
        "    # Swap the last two axis (Time,Freq)\n",
        "    C = torch.transpose(C,-1,-2)\n",
        "    print(C.shape)\n",
        "    return C, torch.Tensor(y)"
      ],
      "metadata": {
        "id": "PPJDUUsrpC07"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try initiating the dataset for debugging\n",
        "ds = lala_dataset(x,y,fs=fs,n_fft=2048,transform =  RandomClip(fraction= 1/3) ,frac_keep = 0.7)\n",
        "# Partition train and validation\n",
        "rtrain = 0.8\n",
        "N = ds.__len__()\n",
        "Ntrain = int(0.8*N)\n",
        "Nval = N - Ntrain\n",
        "ds_train,ds_val = random_split(ds,[Ntrain,Nval])\n",
        "# Define dataloaders\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(ds_train,batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(ds_val,batch_size=1,shuffle=False)"
      ],
      "metadata": {
        "id": "y8d_8Szz6OHK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time for training our model"
      ],
      "metadata": {
        "id": "O_h_qJU4n1XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loops\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(\n",
        "    model = None, \n",
        "    device = 'cuda', \n",
        "    optimizer = None, \n",
        "    scheduler = None,\n",
        "    train_loader = None, \n",
        "    val_loader = None, \n",
        "    num_epochs = 1,\n",
        "    batch_size = 1,\n",
        "):\n",
        "\n",
        "    # Run the first network to\n",
        "    # Epoch loss to return\n",
        "    t_train_loss = []\n",
        "    t_val_loss = []\n",
        "\n",
        "    # Define loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for t in range(num_epochs):\n",
        "      print(f\"------------epoch{t+1}--------------\")\n",
        "      model.train() # train mode\n",
        "      b_train_loss = [] # batch_loss for training\n",
        "      b_val_loss = [] # batch_loss for validation\n",
        "\n",
        "      # Batch loop\n",
        "      for X,Y in tqdm(train_loader):\n",
        "        # zero_gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # get the data needed\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        Ypred = model(X) # The embedding prediction after Mixture with (-1,FT,K)\n",
        "        \n",
        "        # Evaluate the  loss\n",
        "        loss = criterion(Input=Ypred,Target=Y) \n",
        "\n",
        "        # Backprop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Append to b_train_loss (batch)\n",
        "        b_train_loss.append(loss.item()/batch_size)\n",
        "\n",
        "      # Evaluation over validation set\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for X,Y in val_loader:\n",
        "          \n",
        "          X = X.to(device) \n",
        "          Y = Y.to(device)\n",
        "\n",
        "          Ypred = model(X) # The embedding prediction after Mixture with (-1,FT,K)\n",
        "          # evaluate bce loss\n",
        "          loss = criterion(Input=Ypred,Target=Y) \n",
        "\n",
        "          # append to b_val_loss (batch)\n",
        "          b_val_loss.append(loss.item())\n",
        "\n",
        "      \n",
        "      # Save the losses to t_val/t_train loss\n",
        "      t_train_loss.append(np.mean(b_train_loss))\n",
        "      t_val_loss.append(np.mean(b_val_loss))\n",
        "\n",
        "      # Print out the validation loss\n",
        "      print(f'===> Epoch {t+1}: Train Loss -> {t_train_loss[-1]}')\n",
        "      print(f'===> Epoch {t+1}: Validation Loss -> {t_val_loss[-1]}')\n",
        "\n",
        "      # Proceed with schduler\n",
        "      scheduler.step()\n",
        "    # Return dictionary as needed\n",
        "    return {\n",
        "          'train_loss':t_train_loss,\n",
        "          'val_loss':t_val_loss\n",
        "    }\n"
      ],
      "metadata": {
        "id": "RopZQth3EPbW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Define the hyperparameter as well as the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataloader\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(ds_train,batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(ds_val,batch_size=1,shuffle=False)\n",
        "\n",
        "# Model Parameters\n",
        "in_dim = 128 + 1\n",
        "h_dim = 99\n",
        "out_dim = 3 # num class\n",
        "out_len = 1\n",
        "hidden_len = 200\n",
        "n_heads = 3\n",
        "\n",
        "model = set_transformer(in_dim=in_dim,h_dim=h_dim,out_dim=out_dim,out_len=out_len,hidden_len=hidden_len,n_heads=n_heads)\n",
        "model = model.to(device)\n",
        "\n",
        "# Training Parameters\n",
        "lr = 5e-4\n",
        "num_epochs = 1\n",
        "gamma = 0.95\n",
        "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
        "\n",
        "t_losses = train(\n",
        "  model = model, \n",
        "  device = 'cuda', \n",
        "  optimizer = optimizer, \n",
        "  scheduler = scheduler,\n",
        "  train_loader = train_loader, \n",
        "  val_loader = val_loader, \n",
        "  num_epochs = num_epochs,\n",
        "  batch_size = batch_size,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "O5r_JjozFeNu",
        "outputId": "93969097-a44e-4b72-cdc0-71ce17d431f1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------epoch1--------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/18 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([410, 129])\n",
            "torch.Size([410, 129])\n",
            "torch.Size([410, 129])\n",
            "torch.Size([410, 129])\n",
            "torch.Size([4, 410, 129])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/18 [00:02<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 200, 99])\n",
            "torch.Size([4, 410, 99])\n",
            "torch.Size([4, 200, 99])\n",
            "torch.Size([4, 410, 99])\n",
            "torch.Size([4, 1, 99])\n",
            "torch.Size([4, 1, 99])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0352b7c8f75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExponentialLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m t_losses = train(\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-765597dcd158>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, optimizer, scheduler, train_loader, val_loader, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Evaluate the  loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'Input'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-om81lppnz5D"
      }
    }
  ]
}